<!DOCTYPE html>
<html lang="zh-CN">








<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link rel="preconnect" href="//www.googletagmanager.com">
	<link rel="preconnect" href="//zz.bdstatic.com">
	<link rel="preconnect" href="//sp0.baidu.com">
	<link rel="preconnect" href="//www.google-analytics.com">
	<link rel="preconnect" href="//cdn1.lncld.net">
	<link rel="preconnect" href="//unpkg.com">
	<link rel="preconnect" href="//app-router.leancloud.cn">
	<link rel="preconnect" href="//9qpuwspm.api.lncld.net">
	<link rel="preconnect" href="//gravatar.loli.net">

	<title>【预编码论文阅读（二）】深度学习(一) | Levitate_</title>

	<meta name="HandheldFriendly" content="True">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
	<meta name="generator" content="hexo">
	<meta name="author" content="Levitate_">
	<meta name="description" content>

	
	<meta name="keywords" content>
	

	
	<link rel="shortcut icon" href="https://s1.ax1x.com/2022/05/18/Oo3OeI.png">
	<link rel="apple-touch-icon" href="https://s1.ax1x.com/2022/05/18/Oo3OeI.png">
	

	
	<meta name="theme-color" content="#3c484e">
	<meta name="msapplication-TileColor" content="#3c484e">
	

	

	
	<link rel="alternate" href="/atom.xml" title="Levitate_">
	

	<meta property="og:site_name" content="Levitate_">
	<meta property="og:type" content="article">
	<meta property="og:title" content="【预编码论文阅读（二）】深度学习(一) | Levitate_">
	<meta property="og:description" content>
	<meta property="og:url" content="https://levitate-qian.github.io/2021/12/08/precoding-2/">

	
	<meta property="article:published_time" content="2021-12-07T20:12:00+08:00"> 
	<meta property="article:author" content="Levitate_">
	<meta property="article:published_first" content="Levitate_, /2021/12/08/precoding-2/">
	

	
	
	
<link rel="stylesheet" href="/css/allinonecss.min.css">


	
	
	
  <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.0/katex.min.css" rel="stylesheet" type="text/css">
	
<link rel="alternate" href="/atom.xml" title="Levitate_" type="application/atom+xml">
</head>
<body class="post-template">
	<div class="site-wrapper">
		




<header class="site-header post-site-header outer">
    <div class="inner">
        
<nav class="site-nav"> 
    <div class="site-nav-left">
        <ul class="nav">
            <li>
                
                <a href="/" title="Home">HOME</a>
                
            </li>
            
            
            <li>
                <a href="/about" title="ABOUT">ABOUT</a>
            </li>
            
            <li>
                <a href="/archives" title="ARCHIVES">ARCHIVES</a>
            </li>
            
            <li>
                <a href="/links" title="LINKS">LINKS</a>
            </li>
            
            
            <li>
                <p title="公告栏" style="margin: 0px" onclick="disp_notice_alert()">📌</p>
            </li>
        </ul> 
    </div>
    
    <div class="search-button-area">
        <a href="#search" class="search-button">Search ...</a>
    </div>
     
    <div class="site-nav-right">
        
        <a href="#search" class="search-button">Search ...</a>
         
        
<div class="social-links">
    
    
    <a class="social-link" title="github" href="https://github.com/Levitate-Qian/" target="_blank" rel="noopener">
        <svg viewbox="0 0 1049 1024" xmlns="http://www.w3.org/2000/svg"><path d="M524.979332 0C234.676191 0 0 234.676191 0 524.979332c0 232.068678 150.366597 428.501342 358.967656 498.035028 26.075132 5.215026 35.636014-11.299224 35.636014-25.205961 0-12.168395-0.869171-53.888607-0.869171-97.347161-146.020741 31.290159-176.441729-62.580318-176.441729-62.580318-23.467619-60.841976-58.234462-76.487055-58.234463-76.487055-47.804409-32.15933 3.476684-32.15933 3.476685-32.15933 53.019436 3.476684 80.83291 53.888607 80.83291 53.888607 46.935238 79.963739 122.553122 57.365291 152.97411 43.458554 4.345855-33.897672 18.252593-57.365291 33.028501-70.402857-116.468925-12.168395-239.022047-57.365291-239.022047-259.012982 0-57.365291 20.860106-104.300529 53.888607-140.805715-5.215026-13.037566-23.467619-66.926173 5.215027-139.067372 0 0 44.327725-13.906737 144.282399 53.888607 41.720212-11.299224 86.917108-17.383422 131.244833-17.383422s89.524621 6.084198 131.244833 17.383422C756.178839 203.386032 800.506564 217.29277 800.506564 217.29277c28.682646 72.1412 10.430053 126.029806 5.215026 139.067372 33.897672 36.505185 53.888607 83.440424 53.888607 140.805715 0 201.64769-122.553122 245.975415-239.891218 259.012982 19.121764 16.514251 35.636014 47.804409 35.636015 97.347161 0 70.402857-0.869171 126.898978-0.869172 144.282399 0 13.906737 9.560882 30.420988 35.636015 25.205961 208.601059-69.533686 358.967656-265.96635 358.967655-498.035028C1049.958663 234.676191 814.413301 0 524.979332 0z"/></svg>
    </a>
    
    
    
    
    
    <a class="social-link" title="bilibili" href="https://space.bilibili.com/22378236" target="_blank" rel="noopener">
        <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M360.896 183.968l-90.912-88.096s-14.208-17.472 9.824-37.248c24.16-19.648 25.376-10.912 33.504-5.472s135.2 130.816 135.2 130.816zm301.952 3.264l90.912-88.096s14.208-17.472-9.824-37.248c-24.032-19.648-25.376-10.912-33.504-5.472s-135.2 130.816-135.2 130.816zM1004 350.336c-3.264-137.984-123.168-164.192-123.168-164.192s-614.336-4.96-742.496 0C10.176 222.304 20 350.336 20 350.336s1.696 274.272-.128 413.12c13.824 138.848 120.864 160.928 120.864 160.928s42.72.864 73.92.864c3.264 8.992 5.696 52.544 54.24 52.544 48.416 0 54.24-52.544 54.24-52.544s354.88-1.696 384.352-1.696c1.696 14.816 8.992 54.976 57.536 54.24 48.416-.864 51.712-57.536 51.712-57.536s16.384-1.696 65.664 0C997.344 898.88 1004 764.192 1004 764.192s-1.568-275.872 0-413.856zm-98.912 439.232c0 21.728-17.248 39.456-38.464 39.456H167.2c-21.248 0-38.464-17.6-38.464-39.456V326.336c0-21.728 17.248-39.456 38.464-39.456h699.424c21.248 0 38.464 17.6 38.464 39.456zM202.4 457.152l205.344-39.456 15.52 77.184-203.648 39.456zm638.976 0l-205.344-39.456-15.648 77.184 203.776 39.456zm-418.08 191.392s45.152 81.312 95.264-26.336c48.416 105.088 101.824 27.904 101.824 27.904l30.336 19.776s-56.672 91.136-131.424 22.208c-63.232 68.928-129.728-21.952-129.728-21.952z"/></svg>
    </a>
    
    
</div>
    </div>
</nav>
<script type="text/javascript">
function disp_notice_alert()
{
alert("如果出现蓝奏云链接失效，请将链接中的lanzous变为lanzoui即可解决！")
}
</script>
    </div>
</header>


<div id="site-main" class="site-main outer" role="main">
    <div class="inner">
        <header class="post-full-header">
            <div class="post-full-meta">
                <time class="post-full-meta-date" datetime="2021-12-07T20:14:02.000Z">
                    2021-12-07
                </time>
                
                <span class="date-divider">/</span>
                
                <a href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a>&nbsp;&nbsp;
                
                
            </div>
            <h1 class="post-full-title">【预编码论文阅读（二）】深度学习(一)</h1>
        </header>
        <div class="post-full ">
            
            <figure class="post-full-image" style="background-image: url(https://s4.ax1x.com/2021/12/07/ogF99e.png)">
            </figure>
            
            <div class="post-full-content">
                <article id="photoswipe" class="markdown-body">
                    <h1 id="预编码论文阅读（二）——深度学习（一）"><a href="#预编码论文阅读（二）——深度学习（一）" class="headerlink" title="预编码论文阅读（二）——深度学习（一）"></a>预编码论文阅读（二）——深度学习（一）</h1><blockquote>
<p>由于没有非常系统地看完MIMO的相关内容，整理中必定有很多的问题，欢迎在评论区批评指正。</p>
<p>整理很乱。。。</p>
<p>由于网页公式渲染器KaTeX不支持公式交叉引用，我的前端水平就不足以把我这个模板加入mathjax。故将所有公式交叉引用均删除了，有的是在显示不出来的建议贴到markdown里面去吧</p>
</blockquote>
<hr>
<h2 id="Beamforming-Design-for-Large-Scale-Antenna-Arrays-Using-Deep-Learning——2020"><a href="#Beamforming-Design-for-Large-Scale-Antenna-Arrays-Using-Deep-Learning——2020" class="headerlink" title="Beamforming Design for Large-Scale Antenna Arrays Using Deep Learning——2020"></a>Beamforming Design for Large-Scale Antenna Arrays Using Deep Learning——2020</h2><p>MISO-mmWave——maximizing the spectral efficiency (SE) with hardware limitation and imperfect CSI.</p>
<p><img alt="image-20211116102845778" class="post-img b-lazy" data-img="/image-20211116102845778.png" data-index="0" data-src="/image-20211116102845778.png"><br>$$<br>r&#x3D;\mathbf{h}^H\mathbf{v}<em>{RF}s+n<br>$$<br>其中，$\mathbf{v}</em>{RF}\in\mathbb{C}^{N_t\times 1}$</p>
<p>信道矩阵：<br>$$<br>\mathbf{h}^{H}&#x3D;\sqrt{\frac{N_{\mathrm{t}}}{L}} \sum_{l&#x3D;1}^{L} \alpha_{l} \mathbf{a}<em>{\mathrm{t}}^{H}\left(\phi</em>{\mathrm{t}}^{l}\right)<br>$$<br>其中，$L$条路径，$l&#x3D;1$为LoS路径</p>
<p>优化问题——sum-rate problem<br>$$<br>\begin{aligned}<br>\underset{\mathbf{v}<em>{\mathrm{RF}}}{\operatorname{max}} \quad &amp; \log <em>{2}\left(1+\frac{\gamma}{N</em>{\mathrm{t}}}\left|\mathbf{h}^{H} \mathbf{v}</em>{\mathrm{RF}}\right|^{2}\right) \<br>\text { s.t. } \quad &amp;\left|\left[\mathbf{v}<em>{\mathrm{RF}}\right]</em>{i}\right|^{2}&#x3D;1, \quad \text { for } i&#x3D;1, \ldots, N_{\mathrm{t}},<br>\end{aligned}<br>$$<br>$\gamma&#x3D;\frac{P}{\sigma^2}$是信噪比，最优的数字波束赋形$v_D&#x3D;\sqrt{\frac{P}{N_t}}$。约束条件由恒模约束和功率约束。</p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>通过估计的$\mathbf{h}<em>{est},\gamma</em>{est}$优化RF预编码向量$\mathbf{v}<em>{RF}$。相较于CSI，$\gamma</em>{est}&#x3D;\gamma$</p>
<p><img alt="image-20211116141835446" class="post-img b-lazy" data-img="/image-20211116141835446.png" data-index="1" data-src="/image-20211116141835446.png"></p>
<ul>
<li>离线训练：<strong>随机生成信道</strong>（可以获得perfect CSI），输入估计的$\mathbf{h}<em>{est}$，在BFNN中优化$\mathbf{v}</em>{RF}$。再通过$\mathbf{v}_{RF}$和perfect CSI条件下的CSI和信噪比计算Loss函数。——学习在perfect CSI获得理想频谱效率的方法，同时增强信道估计误差的鲁棒性。</li>
<li>在线部署：实际环境信道(imperfect CSI)估计出$\mathbf{h}<em>{est},\gamma</em>{est}$，利用BFNN设计出$\mathbf{v}_{RF}$。</li>
</ul>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img alt="image-20211116142810047" class="post-img b-lazy" data-img="/image-20211116142810047.png" data-index="2" data-src="/image-20211116142810047.png"></p>
<ul>
<li><p>输入：$N_t&#x3D;64$根发射天线，将$N_t&#x3D;64$个信道$\mathbf{h}<em>{est}$的实部、虚部和估计的信噪比$\gamma</em>{est}$作为输入$(2N_t+1)\times 1$</p>
</li>
<li><p>每层开始前先做Batch-Norm</p>
</li>
<li><p>最后输出前通过Lambda层将其变成符合恒模约束的复数矢量$\mathbf{v}<em>{RF}$(由于sigmoid函数，$\alpha_i\in(0,1)$)<br>  $$<br>  \mathbf{v}</em>{RF}&#x3D;\exp(j2\pi\boldsymbol{\alpha})&#x3D;\cos(2\pi\boldsymbol{\alpha})+j\sin(2\pi\boldsymbol{\alpha})<br>  $$</p>
</li>
<li><p>Loss函数：越小越好<br>  $$<br>  Loss&#x3D;-\frac 1N\sum_{n&#x3D;1}^N\log_2\left(1+\frac{\gamma_n}{N_t}\left|\mathbf{h}<em>n^H\mathbf{v}</em>{RF,n} \right|^2\right)<br>  $$</p>
</li>
</ul>
<h3 id="算法复杂度"><a href="#算法复杂度" class="headerlink" title="算法复杂度"></a>算法复杂度</h3><p>每一层的浮点数运算次数是$(2N_I-1)N_O$ ， $N_I$是输入参数个数，$N_O$是输出参数个数。且可以使用并行运算。</p>
<h3 id="仿真"><a href="#仿真" class="headerlink" title="仿真"></a>仿真</h3><p>见BFNN中ffbn_v2.py为pytorch的实数运算版本，ffbn_test.py为测试。ffbn_complex为复数运算版本。</p>
<ul>
<li>注意：$\log_2(A)$使用换底公式通过$\frac{\log(A)}{\log(2)}$实现。</li>
</ul>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li><p>新的设计方法：利用估计的CSI作为BFNN输入，直接输出最优beamforming权值。估计的信道矩阵$\mathbf{h}<em>{\mathrm{est}}$ ,估计的信噪比$\gamma</em>{\text {est }}$作为输入。</p>
</li>
<li><p>新颖的Loss函数：在作者的设计中不需要标签，创新性地提出了与SE十分相关的一个Loss函数<br>  $$<br>  \text { Loss }&#x3D;-\frac{1}{N} \sum_{n&#x3D;1}^{N} \log <em>{2}\left(1+\frac{\gamma</em>{n}}{N_{\mathrm{t}}}\left|\mathbf{h}<em>{n}^{H} \mathbf{v}</em>{\mathrm{RF}, n}\right|^{2}\right)<br>  $$<br>  Loss函数的减少正好对应着平均SE的增加</p>
</li>
<li><p>对于非理性CSI的鲁棒性：提出了一种两阶段设计方法，利用估计的CSI作为输入，让BFNN学会接近理想CSI下的SE。在线部署阶段，BFNN能够适应非理性CS实现对信道估计误差的鲁棒性。</p>
</li>
<li><p>Lamda层满足恒模约束：经典的、完美的欧拉公式<br>  $$<br>  \mathbf{v}_{\mathrm{RF}}&#x3D;\exp (\mathrm{j} \cdot \boldsymbol{\theta})&#x3D;\cos (\boldsymbol{\theta})+{j} \cdot \sin (\boldsymbol{\theta})<br>  $$<br>  将相位$\boldsymbol{\theta}$作为在最后一个Dense层的输出，然后添加一个基于欧拉公式的Lamda层满足恒模约束。</p>
</li>
</ul>
<h3 id="改进思路"><a href="#改进思路" class="headerlink" title="改进思路"></a>改进思路</h3><p>略</p>
<hr>
<h2 id="A-Deep-Learning-Framework-for-Optimization-of-MISO-Downlink-Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM"><a href="#A-Deep-Learning-Framework-for-Optimization-of-MISO-Downlink-Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM" class="headerlink" title="A Deep Learning Framework for Optimization of MISO Downlink Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM"></a>A Deep Learning Framework for Optimization of MISO Downlink Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM</h2><p>有约束！</p>
<p>MU-MISO<br>$$<br>y_k&#x3D;\mathbf{h}<em>k^H\sum</em>{i&#x3D;1}^K\mathbf{w}_ix_i+n_k<br>$$<br>其中，$\mathbf{h}_k\in \mathbb{C}^{N\times 1}$ ， $x_i\sim\mathcal{CN}(0,1),n_i\sim\mathcal{CN}(0,\sigma^2)$</p>
<p>本文解决的问题：(P1、P2可以解得最优解，可采用监督学习；P3非凸，无最优解)</p>
<ul>
<li><p>SINR balancing problem under a total power constraint,<br>  $$<br>  \begin{aligned}<br>  \mathbf{P1:}\underset{\mathbf{W}}{\operatorname{maximize}} \quad &amp; \min_{1 \leq k \leq K}\left{ \frac{\gamma_{k}^{d l}}{\rho_{k}}\right}, \<br>  \text { s.t. } \quad&amp;\sum_{k&#x3D;1}^{K}\left|\mathbf{w}<em>{k}\right|^{2} \leq P</em>{\max }<br>  \end{aligned}<br>  $$<br>  $\rho_k$是importance of the sub-streams，$\mathbf{W}&#x3D;[\mathbf{w_1,w_2,\cdots,w_K}]$ ， $P_{\max}$是power budget</p>
</li>
<li><p>power minimization problem under QoS(Quality of Service) constraints,<br>  $$<br>  \begin{aligned}<br>  \mathbf{P2:}\min_{\mathbf{W}} \quad&amp; \sum_{k&#x3D;1}^K||\mathbf{w}_k||^2\<br>  \mathrm{s.t.}\quad&amp;\gamma_k^{dl}\ge \Gamma_k,\forall k.<br>  \end{aligned}<br>  $$<br>  $\boldsymbol{\Gamma}&#x3D;[\Gamma_1,\cdots,\Gamma_K]^T$是SINR constraint</p>
</li>
<li><p>sum rate maximization problem under a total power constraint.<br>  $$<br>  \begin{aligned}<br>  \mathbf{P3:}\max_{\mathbf{W}}\quad&amp;\sum_{k&#x3D;1}^K\alpha_k\log_2(1+\gamma_k^{dl})\<br>  \mathrm{s.t.}\quad&amp;\sum_{k&#x3D;1}^{K}\left|\mathbf{w}<em>{k}\right|^{2} \leq P</em>{\max }<br>  \end{aligned}<br>  $$</p>
</li>
</ul>
<h3 id="网络框架"><a href="#网络框架" class="headerlink" title="网络框架"></a>网络框架</h3><p><img alt="image-20211118151957384" class="post-img b-lazy" data-img="/image-20211118151957384.png" data-index="3" data-src="/image-20211118151957384.png"></p>
<p>A DL-based framework for the beamforming optimization in MISO downlink, which includes two main modules: <strong>the neural network module and the beamforming recovery module</strong>. The neural network module is composed of an input layer, convolutional (CL) layers, batch normalization (BN) layers, activation (AC) layers, a flatten layer, a fully-connected (FC) layer, and an output layer, whereas the key features and the functional layers in the beamforming recovery module are specified by the expert knowledge.</p>
<ul>
<li><p>输入层：$\mathbf{h}&#x3D;[\mathbf{h}_1^H,\cdots,\mathbf{h}_K^H]^H\in\mathbb{C}^{NK\times1}$–&gt;I&#x2F;Q transformation–&gt;$[\mathfrak{R}(\mathbf{h}),\mathfrak{I}(\mathbf{h})]^T\in\mathbb{R}^{2\times NK}$</p>
</li>
<li><p>本文，BN在CONV前进行</p>
</li>
<li><p>MSE loss对异常值敏感，但数据集由仿真产生，故仍采用MSE</p>
</li>
<li><p>比起完全预测整个BF矩阵，专家知识可以有效减小需要预测的变量</p>
</li>
</ul>
<h3 id="P1（功率约束下SINR平衡）的网络——supervised"><a href="#P1（功率约束下SINR平衡）的网络——supervised" class="headerlink" title="P1（功率约束下SINR平衡）的网络——supervised"></a>P1（功率约束下SINR平衡）的网络——supervised</h3><p>通过$\mathbf{h}$预测上行链路power allocation矢量$\mathbf{\hat q}$（最优值通过迭代获得【ai2-12】），再通过上行链路-下行链路二元性，得到下行链路的最优功率分配矢量$\mathbf{p}^*$和BF矢量$\mathbf{\tilde W}^*$，有$\mathbf{W}^*&#x3D;\mathbf{\tilde W}^<em>\mathbf{P}^</em>$</p>
<p><img alt="image-20211118171020326" class="post-img b-lazy" data-img="/image-20211118171020326.png" data-index="4" data-src="/image-20211118171020326.png"></p>
<ul>
<li><p>除了最后一个激活函数为Sigmoid，其它均为ReLU</p>
</li>
<li><p>Scaling——满足功率限制<br>  $$<br>  \mathbf{\hat q}^*&#x3D;\frac{P_{\max}}{||\mathbf{\hat q}||_1}\mathbf{\hat q}<br>  $$</p>
</li>
<li><p>conversion——由$\mathbf{\hat q}^*$求$\mathbf{\hat W}^*$<br>  <img alt="image-20211119104539898" class="post-img b-lazy" data-img="/image-20211119104539898.png" data-index="5" data-src="/image-20211119104539898.png"></p>
</li>
<li><p>Loss函数采用MSE度量</p>
</li>
</ul>
<h3 id="P2（服务质量约束下功率最小）的网络"><a href="#P2（服务质量约束下功率最小）的网络" class="headerlink" title="P2（服务质量约束下功率最小）的网络"></a>P2（服务质量约束下功率最小）的网络</h3><p>同样，通过$\mathbf{h}$预测上行链路power allocation矢量$\mathbf{\hat q}$（最优值通过迭代获得【ai2-5】），再通过上行链路-下行链路二元性，得到下行链路的最优功率分配矢量$\mathbf{p}^*$和BF矢量$\mathbf{\tilde W}^*$，有$\mathbf{W}^*&#x3D;\mathbf{\tilde W}^<em>\mathbf{P}^</em>$。<strong>但无功率约束，不需要上行链路power allocation矢量归一化。</strong></p>
<ul>
<li>conversion<br>  <img alt="image-20211119111841965" class="post-img b-lazy" data-img="/image-20211119111841965.png" data-index="6" data-src="/image-20211119111841965.png"><img alt="image-20211119111852718" class="post-img b-lazy" data-img="/image-20211119111852718.png" data-index="7" data-src="/image-20211119111852718.png"></li>
<li>与P1不同，当$\mathbf{\hat q}^*$与实际优化值$\mathbf{q}^*$相差过大时，会导致$\mathbf{\hat p}^*$不符合物理规律从而导致波束成型不可行</li>
</ul>
<h3 id="P3（功率约束下SR最高）的网络"><a href="#P3（功率约束下SR最高）的网络" class="headerlink" title="P3（功率约束下SR最高）的网络"></a>P3（功率约束下SR最高）的网络</h3><p><img alt="image-20211119150331158" class="post-img b-lazy" data-img="/image-20211119150331158.png" data-index="8" data-src="/image-20211119150331158.png"></p>
<p>Sum-rate优化问题没有最优解。</p>
<ul>
<li><p><strong>第一阶段</strong>先通过监督学习逼近传统WMMSE算法的局部最优解，称为“预训练”<br>  $$<br>  Loss&#x3D;\frac{1}{2LK}\sum_{l&#x3D;1}^L\left(\left|\mathbf{\underline p}^{(l)}-\mathbf{\hat p}^{(l)}\right|_2^2+\left|\boldsymbol{\underline \lambda}^{(l)}-\boldsymbol{\hat \lambda}^{(l)}\right|_2^2\right)<br>  $$<br>  其中，$\mathbf{p}$是BF的功率分配矢量，$\boldsymbol{\lambda}$是lagrange乘子，可以看作虚拟的功率分配矢量。</p>
</li>
<li><p><strong>第二阶段</strong>直接计算这个算法的优化目标函数作为loss，进行无监督学习。<br>  $$<br>  \text { Loss }&#x3D;-\frac{1}{2 K L} \sum_{l&#x3D;1}^{L} \underbrace{\sum_{k&#x3D;1}^{K} \alpha_{k}^{(l)} \log <em>{2}\left(1+\gamma</em>{k}^{u l,(l)}\right)}_{sum-rate}<br>  $$</p>
</li>
<li><p>分两个阶段的作用：显著增强学习效果，加快收敛。（杨神：？）</p>
</li>
<li><p>scaling——满足功率约束，$2K$个参数<br>  $$<br>  \mathbf{\hat p}^*&#x3D;\frac{P_{\max}}{||\mathbf{\hat p}||<em>1}\mathbf{\hat p}\quad\text{and}\quad\boldsymbol{\hat \lambda}^*&#x3D;\frac{P</em>{\max}}{||\boldsymbol{\hat \lambda}||_1}\boldsymbol{\hat \lambda}<br>  $$</p>
</li>
<li><p>construction——$P_{\max}$和$\sum_{k&#x3D;1}^K\lambda_i&#x3D;P_{\max}$是lagrange对偶问题【ai2-2】<br>  $$<br>  \hat{\mathbf{w}}<em>{k}^{*}&#x3D;\sqrt{\hat{p}</em>{k}^{<em>}} \frac{\left(\mathbf{I}<em>{N}+\sum</em>{k&#x3D;1}^{K} \frac{\hat{\lambda}_{k}^{</em>}}{\sigma^{2}} \mathbf{h}<em>{k} \mathbf{h}</em>{k}^{H}\right)^{-1} \mathbf{h}<em>{k}}{\left|\left(\mathbf{I}</em>{N}+\sum_{k&#x3D;1}^{K} \frac{\hat{\lambda}<em>{k}^{*}}{\sigma^{2}} \mathbf{h}</em>{k} \mathbf{h}<em>{k}^{H}\right)^{-1} \mathbf{h}</em>{k}\right|_{2}}, \quad \forall k<br>  $$</p>
</li>
</ul>
<h3 id="仿真-1"><a href="#仿真-1" class="headerlink" title="仿真"></a>仿真</h3><p><img alt="image-20211120104337880" class="post-img b-lazy" data-img="/image-20211120104337880.png" data-index="9" data-src="/image-20211120104337880.png"></p>
<h3 id="contributions"><a href="#contributions" class="headerlink" title="contributions"></a>contributions</h3><ul>
<li>所提出的框架利用了专家知识，如上行链路和下行链路的二元性以及已知的最佳解决方案的结构。这种知识通过允许人们指定要学习的最佳参数来提高精简效率；这些参数通常不是波束成形矩阵条目。</li>
</ul>
<h3 id="改进思路——针对SR的思考"><a href="#改进思路——针对SR的思考" class="headerlink" title="改进思路——针对SR的思考"></a>改进思路——针对SR的思考</h3><p>略</p>
<hr>
<h2 id="Deep-Learning-Enabled-Optimization-of-Downlink-Beamforming-Under-Per-Antenna-Power-Constraints-Algorithms-and-Experimental-Demonstration——2020-TWC"><a href="#Deep-Learning-Enabled-Optimization-of-Downlink-Beamforming-Under-Per-Antenna-Power-Constraints-Algorithms-and-Experimental-Demonstration——2020-TWC" class="headerlink" title="Deep Learning Enabled Optimization of Downlink Beamforming Under Per-Antenna Power Constraints: Algorithms and Experimental Demonstration——2020-TWC"></a>Deep Learning Enabled Optimization of Downlink Beamforming Under Per-Antenna Power Constraints: Algorithms and Experimental Demonstration——2020-TWC</h2><p>三类DL处理的问题：</p>
<ul>
<li>One of the areas of interest is to deal with scenarios in which the channel<br>  model does not exist, 传统信道模型不存在</li>
<li>Another area of interest is to optimize the end-to-end system performance，对端到端系统的优化</li>
<li>The third area of interest is to overcome the complexity of wireless networks，无线网络的复杂度问题</li>
</ul>
<p>在上一篇文章的基础上增加了单天线约束（过去大部分文章讨论MU-MISO，即基站多天线用户单天线问题）</p>
<p>在基站侧单天线功率约束下，最大化最小接收信干噪比或平衡信干噪比</p>
<p>——独立的非频选瑞利快衰落</p>
<p>波束赋形矩阵：$\mathbf{W}&#x3D;[\mathbf{w_1,w_2,\cdots,w_K}]\in\mathbb{C}^{N_t\times K}$。单天线约束为<br>$$<br>p_n&#x3D;\left|\mathbf{W}(n,:) \right|^2&#x3D;\left|\mathbf{e}_n\mathbf{W} \right|^2<br>$$<br>其中，$\mathbf{e}_n$是除了第$n$个元素为1外的零矢量。</p>
<h3 id="单天线约束下的SINR-balancing问题："><a href="#单天线约束下的SINR-balancing问题：" class="headerlink" title="单天线约束下的SINR balancing问题："></a>单天线约束下的SINR balancing问题：</h3><p>$$<br>\begin{aligned}<br>\textbf { P1: } \max <em>{\mathbf{W}, \Gamma} \quad &amp;\Gamma  \<br>\text { s.t. }\quad&amp;  \gamma</em>{k} &#x3D;\frac{\left|\mathbf{h}<em>{k}^{T} \mathbf{w}</em>{k}\right|^{2}}{\sum_{i&#x3D;1, i \neq k}^{K}\left|\mathbf{h}<em>{k}^{T} \mathbf{w}</em>{i}\right|^{2}+N_{0}} \geq \Gamma, \quad \forall k, \<br>&amp; p_{n} &#x3D;\left|\mathbf{e}<em>{n}^{T} \mathbf{W}\right|^{2} \leq P</em>{n}, \quad \forall n .<br>\end{aligned}<br>$$</p>
<p>通过广义特征值算法，可以转化为问题P2<br>$$<br>\begin{aligned}<br>\mathbf{P 2}:  \max <em>{\beta, \boldsymbol{\lambda}, \boldsymbol{\mu}}\quad &amp; \beta \<br> \text { s.t. } \quad&amp;\beta \lambda</em>{k} \mathbf{h}<em>{k}^{T} \mathbf{G}(\boldsymbol{\lambda}, \boldsymbol{\mu})^{-1} \mathbf{h}</em>{k}^{<em>} \leq 1, \quad \forall k, \<br>&amp; \sum_{k&#x3D;1}^{K} \lambda_{k} N_{0}&#x3D;1, \<br>&amp; \sum_{n&#x3D;1}^{N_{t}} \mu_{n} P_{n}&#x3D;1, \<br>&amp; \boldsymbol{\lambda}, \boldsymbol{\mu}, \beta \geq \mathbf{0} .<br>\end{aligned}<br>$$<br>其中，$\mathbf{G}(\boldsymbol{\lambda}, \boldsymbol{\mu})\triangleq\sum_{i&#x3D;1}^K\lambda_i\mathbf{h}_i^</em>\mathbf{h}_i^T+diag(\boldsymbol{\mu})$，</p>
<ul>
<li>$\boldsymbol{\lambda}\in\mathbb{Z}^K$与SINR约束相关,</li>
<li>$\boldsymbol{\mu}\in\mathbb{Z}^{N_t}$与单天线约束相关，</li>
</ul>
<p>$\beta&#x3D;1+\frac{1}{\Gamma}$。</p>
<p>The optimal downlink beamforming problem <strong>P2</strong> with per-antenna power constraints can be solved via a dual uplink channel in which the SINR constraints remain the same and the noise is uncertain. 通过对偶性转化成上行链路问题P3$\max_{\boldsymbol{\mu}}\max_{\Gamma,\boldsymbol{\lambda}} \Gamma$ ，P3是两个max嵌套，内层的max是$\mathbf{u}$的函数，先求解内层问题P4$f(\mathbf{u})&#x3D;\max_{\Gamma,\boldsymbol{\lambda}} \Gamma$，再通过subgradient算法，求解外层关于$\boldsymbol{\mu}$的问题。</p>
<p><img alt="image-20211121155315628" class="post-img b-lazy" data-img="/image-20211121155315628.png" data-index="10" data-src="/image-20211121155315628.png"></p>
<h3 id="流程-1"><a href="#流程-1" class="headerlink" title="流程"></a>流程</h3><p>two strategies：</p>
<ul>
<li>one is to learn the dual variables <em><strong>μ</strong></em> and <em><strong>λ</strong></em> with fast recovery of the original beamforming solution,——算法类似A2，但不需要更新</li>
<li>the other is to learn only the dual variable <em><strong>μ</strong></em> with improved learning accuracy, to achieve various tradeoffs.——只通过神经网络估计$\boldsymbol{\mu}$，而$\boldsymbol{\lambda}$通过算法1求解，可以更精确</li>
</ul>
<p>DL结构的一般性：由于用户数量$K$和发射天线数量$N_t$会发生变化，所以要采取相应措施保证其泛化能力。</p>
<ul>
<li>Transfer learning——【ai3-52】</li>
<li>training set augmentation（训练集扩大）——训练集中样本的$N_t,K$不固定，但是输入输出固定为$2\times N_t’K’$和$K’$ ， $N_t’&gt;N_t,K’&gt;K$，多的补零。（杨神：？）</li>
</ul>
<h3 id="仿真-2"><a href="#仿真-2" class="headerlink" title="仿真"></a>仿真</h3><p>本文提出的和优化算法针对信道估计误差是鲁棒的。</p>
<p>当$N_t\geq K$则ZF需要解决复杂度更高的SOCP问题。</p>
<h3 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h3><ul>
<li>提出了subgradient算法，收敛更快</li>
<li>提出了学习双变量的DL框架</li>
<li>开发了一种启发式算法，通过数据augmentation适应不同的用户数和天线数，提高泛化能力（？）</li>
<li>testbed实验</li>
</ul>
<hr>
<h2 id="IAIDNN——2021-TWC"><a href="#IAIDNN——2021-TWC" class="headerlink" title="IAIDNN——2021-TWC"></a>IAIDNN——2021-TWC</h2><p><em>Iterative Algorithm Induced Deep-Unfolding Neural Networks: Precoding Design for Multiuser MIMO Systems</em></p>
<blockquote>
<p>本文部分链接和引用没法用，链接的是预编码论文阅读（一）中迭代的那篇文章“<em>An Iteratively Weighted MMSE Approach to Distributed Sum-Utility Maximization for a MIMO Interfering Broadcast Channel</em>”</p>
</blockquote>
<p>建模同文章“<em>An Iteratively Weighted MMSE Approach to Distributed Sum-Utility Maximization for a MIMO Interfering Broadcast Channel</em>”</p>
<p><img alt="image-20211104143313382" class="post-img b-lazy" data-img="https://z3.ax1x.com/2021/11/08/I8Sr9A.png" data-index="11" data-src="https://z3.ax1x.com/2021/11/08/I8Sr9A.png"></p>
<h3 id="深度展开网络的搭建"><a href="#深度展开网络的搭建" class="headerlink" title="深度展开网络的搭建"></a>深度展开网络的搭建</h3><ul>
<li><p>优化问题（目标函数）：<br>  $$<br>  \min_\mathbf{X}\quad \mathbb{E}_\mathbf{Z}{f(\mathbf{X};\boldsymbol{\theta},\mathbf{Z})},\quad\text{s.t.}\ \mathbf{X}\in\mathcal{X}<br>  $$<br>  其中，$\boldsymbol{\theta}$是可以训练的参数，$\mathbf{X}$是变量，$\mathbf{Z}$是随机参数</p>
</li>
<li><p>前向传播：<br>  $$<br>  \mathbf{X}^l&#x3D;\mathcal{F}_l(\mathbf{X}^{l-1};\boldsymbol{\theta},\mathbf{Z})<br>  $$<br>  在本文中，前向传播的模型为<br>  $$<br>  \mathbf{X}^l&#x3D;\bar{\mathbf{A}}\mathbf{X}^{l-1}\bar{\mathbf{B}}\mathbf{X}^{l-1}\bar{\mathbf{C}}+\varphi(\bar{\mathbf{A}}\mathbf{X}^{l-1}\bar{\mathbf{B}}\mathbf{X}^{l-1}\bar{\mathbf{C}})\bar{\mathbf{D}}<br>  $$</p>
</li>
<li><p>反向传播：GCR in Matrix Form（更一般的链式法则）<br>  $$<br>  \begin{aligned}<br>  &amp;\operatorname{Tr}\left{\mathbf{G}^{l} d \mathbf{X}^{l}\right} \<br>  &amp;\stackrel{(5)}{&#x3D;} \operatorname{Tr}\left{\left(\overline{\mathbf{B}} \mathbf{X}^{l-1} \overline{\mathbf{C}} \mathbf{G}^{l}\left(\overline{\mathbf{D}} \circ \varphi^{\prime}\left(\overline{\mathbf{A}} \mathbf{X}^{l-1} \overline{\mathbf{B}} \mathbf{X}^{l-1} \overline{\mathbf{C}}\right)^{T}+\mathbf{I}\right) \overline{\mathbf{A}}\right.\right. \<br>  &amp;\left.\left.\quad+\overline{\mathbf{C}} \mathbf{G}^{l}\left(\overline{\mathbf{D}} \circ \varphi^{\prime}\left(\overline{\mathbf{A}} \mathbf{X}^{l-1} \overline{\mathbf{B}} \mathbf{X}^{l-1} \overline{\mathbf{C}}\right)^{T}+\mathbf{I}\right) \overline{\mathbf{A}} \mathbf{X}^{l-1} \overline{\mathbf{B}}\right) d \mathbf{X}^{l-1}\right}<br>  \end{aligned}<br>  $$<br>  $\mathbf{G}^l$是$\mathbf{X}^l$的梯度，$\circ$是element-wise。</p>
</li>
<li><p><strong>该网络的创新点：</strong>In comparison with applying the platforms such as “Pytorch” and “Tensorflow” to do the BP, the GCR has three advantages</p>
<ul>
<li>The platforms cannot do BP for the complex trainable parameters;</li>
<li>There are some operations these platforms cannot do, such as the inversion and the determinant of a complex matrix; </li>
<li>Based on the GCR, the closed-form gradients are obtained, which is more accurate and provides faster convergence speed compared with the automatic differential of the platforms.</li>
<li><strong>Then, based on the GCR presented in Theorem 1, the gradient in each layer, i.e., ${\mathbf{G}^l,l\in\mathcal{L}}$ is obtained. Finally, the gradient of trainable parameter $\boldsymbol{\theta}^l$ is calculated based on $\mathbf{G}^l$.</strong></li>
</ul>
</li>
</ul>
<h3 id="IWMMSE算法的转换"><a href="#IWMMSE算法的转换" class="headerlink" title="IWMMSE算法的转换"></a>IWMMSE算法的转换</h3><p>将功率限制，考虑到$\eqref{eq:2-1}$的目标函数中，考虑无约束的SR问题(13)<br>$$<br>\begin{aligned}<br>\max <em>{\left{\mathbf{V}</em>{k}\right}} \quad&amp; \sum_{k&#x3D;1}^{K} \omega_{k} \log \operatorname{det}\left(\mathbf{I}+\mathbf{H}<em>{k} \mathbf{V}</em>{k} \mathbf{V}<em>{k}^{H} \mathbf{H}</em>{k}^{H}\right.\<br>&amp;\left.\left(\sum_{m \neq k} \mathbf{H}<em>{k} \mathbf{V}</em>{m} \mathbf{V}<em>{m}^{H} \mathbf{H}</em>{k}^{H}+\frac{\sigma_{k}^{2}}{P_{T}} \sum_{n&#x3D;1}^{K} \operatorname{Tr}\left(\mathbf{V}<em>{n} \mathbf{V}</em>{n}^{H}\right) \mathbf{I}\right)^{-1}\right)<br>\end{aligned}<br>$$<br>式$\eqref{eq:ai4-13}$的最优解$\mathbf{V}^{\star\star}$和式$\eqref{eq:2-1}$的最优解$\mathbf{V}^{\star}$存在关系:<br>$$<br>\mathbf{V}<em>k^{\star}&#x3D;\alpha\mathbf{V}<em>k^{\star\star},\quad\alpha&#x3D;\frac{\sqrt{P_T}}{\left(\sum</em>{k&#x3D;1}^K Tr(\mathbf{V}<em>k^{\star\star}(\mathbf{V}<em>k^{\star\star})^H) \right)^{\frac12}}<br>$$<br>进一步考虑，MMSE问题和WSR问题的同一性，将问题就转换成了无约束的MMSE问题<br>$$<br>\min <em>{\left{\mathbf{W}</em>{k}, \mathbf{U}</em>{k}, \mathbf{V}</em>{k}\right}} \sum</em>{k&#x3D;1}^{K} \omega_{k}\left(\operatorname{Tr}\left(\mathbf{W}<em>{k} \mathbf{E}</em>{2, k}\right)-\log \operatorname{det}\left(\mathbf{W}<em>{k}\right)\right)<br>$$<br>其中，<br>$$<br>\begin{aligned}<br>&amp;\mathbf{E}</em>{2, k} \triangleq\left(\mathbf{I}-\mathbf{U}<em>{k}^{H} \mathbf{H}</em>{k} \mathbf{V}<em>{k}\right)\left(\mathbf{I}-\mathbf{U}</em>{k}^{H} \mathbf{H}<em>{k} \mathbf{V}</em>{k}\right)^{H} \<br>&amp;+\sum_{m \neq k} \mathbf{U}<em>{k}^{H} \mathbf{H}</em>{k} \mathbf{V}<em>{m} \mathbf{V}</em>{m}^{H} \mathbf{H}<em>{k}^{H} \mathbf{U}</em>{k}+\frac{\sum_{n&#x3D;1}^{K} \operatorname{Tr}\left(\mathbf{V}<em>{n} \mathbf{V}</em>{n}^{H}\right)}{P_{T}} \sigma_{k}^{2} \mathbf{U}<em>{k}^{H} \mathbf{U}</em>{k}<br>\end{aligned}<br>$$<br>算法流程图：</p>
<p><img alt="image-20211123150620802" class="post-img b-lazy" data-img="/image-20211123150620802.png" data-index="12" data-src="/image-20211123150620802.png"></p>
<p><img alt="image-20211123150646333" class="post-img b-lazy" data-img="/image-20211123150646333.png" data-index="13" data-src="/image-20211123150646333.png"></p>
<p>与上述分析的深度展开网络中参数的对照：<br>$$<br>\begin{aligned}<br>\mathbf{X}\equiv&amp;\left{\mathbf{W}_k,\mathbf{U}_k,\mathbf{V}_k,\forall k\in\mathcal{K} \right}\<br>\mathbf{Z}\equiv&amp;\left{\mathbf{H}_k,\omega_k,\sigma_k,P_T,\forall k\in\mathcal{K} \right}<br>\end{aligned}<br>$$<br>迭代过程：<br>$$<br>\begin{aligned}<br>\mathbf{U}^t&#x3D;&amp;F_t(\mathbf{V}^{t-1})\<br>\mathbf{W}^t&#x3D;&amp;G_t(\mathbf{U}^t,\mathbf{V}^{t-1})\<br>\mathbf{V}^t&#x3D;&amp;J_t(\mathbf{U}^t,\mathbf{W}^t)<br>\end{aligned}<br>$$</p>
<h3 id="IAIDNN-iterative-algorithm-induced-Deep-Unfolding-Neural-Network"><a href="#IAIDNN-iterative-algorithm-induced-Deep-Unfolding-Neural-Network" class="headerlink" title="IAIDNN(iterative algorithm induced Deep-Unfolding Neural Network)"></a>IAIDNN(iterative algorithm induced Deep-Unfolding Neural Network)</h3><h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><ul>
<li>减小矩阵求逆的计算量的两种途径<ul>
<li>用$\mathbf{A}^+&#x3D;(\mathbf{A}\circ\mathbf{I})^{-1}$逼近$\mathbf{A}^{-1}$，因为对角元比非对角元大得多&#x3D;&gt;训练$\mathbf{A^+X}$中的$\mathbf{X}$</li>
<li>用$\mathbf{A}^{-1}$的一阶taylor展开$2\mathbf{A}_0^{-1}-\mathbf{A}_0^{-1}\mathbf{AA}_0^{-1}$逼近&#x3D;&gt;训练$\mathbf{AY+Z}$中的$\mathbf{Y,Z}$</li>
<li>【？】用$\mathbf{A^+X+AY+Z}$来逼近$\mathbf{A}^{-1}$</li>
</ul>
</li>
<li>迭代算法中$\mathbf{U,W,V}$的估计均用此法估计，同时$\mathbf{U,V}$的估计还有训练补偿(offset)$\left{\mathbf{O}_k^{u,l+1},\mathbf{O}_k^{v,l+1} \right}$</li>
<li>$\mathbf{V}$的维数比$\mathbf{U,W}$的维数大得多，将$\mathbf{U,W}$作为网络的输出，将$\mathbf{V}$对$\mathbf{U,W}$的表达式作为网络的Loss<br>  <img alt="image-20211124123855835" class="post-img b-lazy" data-img="/image-20211124123855835.png" data-index="14" data-src="/image-20211124123855835.png"></li>
<li>Loss函数：</li>
</ul>
<p>$$<br>\max <em>{\left{\mathbf{V}</em>{k}\right}} \sum_{k&#x3D;1}^{K} \mathbb{E}<em>{\mathbf{H}</em>{k}}\left{\omega_{k} \log \operatorname{det}\left(\mathbf{I}+\mathbf{H}<em>{k} \mathbf{V}</em>{k} \mathbf{V}<em>{k}^{H} \mathbf{H}</em>{k}^{H}\left(\sum_{m \neq k} \mathbf{H}<em>{k} \mathbf{V}</em>{m} \mathbf{V}<em>{m}^{H} \mathbf{H}</em>{k}^{H}+\frac{\sigma_{k}^{2}}{P_{T}} \sum_{k} \operatorname{Tr}\left(\mathbf{V}<em>{k} \mathbf{V}</em>{k}^{H}\right) \mathbf{I}\right)^{-1}\right)\right}<br>$$</p>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p><strong>反向传播不直接对训练参数进行计算，而先对中间的迭代变量进行计算！</strong></p>
<ul>
<li>对迭代变量$\mathbf{U,W,V}$的梯度：<ul>
<li>最后一层由目标函数代入$\mathbf{V}_k^L$的表达式，对$\mathbf{U_k^L,W_k^L}$求梯度$\mathbf{G_k^{u,L}},\mathbf{G_k^{v,L}}$</li>
<li>中间层由GCR算法，从$l+1$层的对$\mathbf{U,W,V}$的梯度计算得到$l$层的梯度</li>
</ul>
</li>
<li>进一步通过链式法则求解出训练参数的梯度<br>  <img alt="image-20211124164004293" class="post-img b-lazy" data-img="/image-20211124164004293.png" data-index="15" data-src="/image-20211124164004293.png"></li>
<li>采取梯度下降方法训练网络</li>
<li>初始值的选定：训练参数随机初始化；$\mathbf{V}^0_k$用ZF初始化</li>
</ul>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p><img alt="image-20211124131151072" class="post-img b-lazy" data-img="/image-20211124131151072.png" data-index="16" data-src="/image-20211124131151072.png"></p>
<p><img alt="image-20211124131216620" class="post-img b-lazy" data-img="/image-20211124131216620.png" data-index="17" data-src="/image-20211124131216620.png"></p>
<h3 id="benchmark——CNN"><a href="#benchmark——CNN" class="headerlink" title="benchmark——CNN"></a>benchmark——CNN</h3><p>类似【ai2】，</p>
<ul>
<li>输入：$\mathbf{H}\triangleq [\mathbf H_1^T,\mathbf H_2^T,\cdots,\mathbf H_k^T]^T$</li>
<li>输出：$\mathbf{U_k,W_k}$</li>
<li>流程：<ul>
<li>监督：先逼近传统的WMMSE，用求$\mathbf{U,W}$的MSE作为loss</li>
<li>无监督：再用代入$\mathbf V_k$的SR作为loss</li>
</ul>
</li>
</ul>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><ul>
<li><p>参数</p>
<ul>
<li><p>IAIDNN的参数维度取决于需要训练的参数$\left{\mathbf X_k^{u,l},\mathbf Y_k^{u,l},\mathbf Z_k^{u,l},\mathbf O_k^{u,l}\right}$,$\left{\mathbf X_k^{w,l},\mathbf Y_k^{w,l},\mathbf Z_k^{w,l}\right}$,$\left{\mathbf X_k^{v,l},\mathbf Y_k^{v,l},\mathbf Z_k^{v,l},\mathbf O_k^{v,l}\right}$，最后一层无$\mathbf V$相关的参数<br>  $$<br>  \begin{aligned}<br>  \text{普通中间层：}&amp;\left(3 N_{r}^{2}+3 d^{2}+3 N_{t}^{2}+d N_{r}+d N_{t}\right) K\<br>  \text{最后一层：}&amp;L K\left(3 N_{r}^{2}+3 d^{2}+d N_{r}\right)+(L-1) K\left(3 N_{t}^{2}+d N_{t}\right)<br>  \end{aligned}<br>  $$</p>
</li>
<li><p>CNN<br>  $$<br>  \sum_{l&#x3D;1}^{L-2} S_{l}^{2} C_{l-1} C_{l}+K N_{r} N_{t} C_{L-2} C_{\text {out }}<br>  $$<br>  卷积核$S_l&#x3D;5$，通道数$C_l&#x3D;32$，全连接层输出$C_{out}&#x3D;1024$</p>
</li>
</ul>
</li>
<li><p>复杂度</p>
<ul>
<li>传统WMMSE需要迭代$L_W$次，但IAIDNN只有$L_a$层，$L_a\ll L_w$</li>
<li>相比传统的矩阵求逆需要$\mathcal{O}(n^3)$，本文中的近似只需要$\mathcal{O}(n^{2.37})$</li>
<li>IAIDNN的闭式梯度比传统黑箱CNN训练时间更短、效果更好</li>
</ul>
</li>
<li><p>泛化能力</p>
<ul>
<li>同【ai3】可以训练$(N_{t0},N_{r0},K_0)$的网络，但实际情景$(N_{t1},N_{r1},K_1)$时，$(N_{t1}&lt;N_{t0},N_{r1}&lt;N_{t0},K_1&lt;K_{0})$也是可行的（这篇文章我觉得时可行的，因为都是矩阵运算）</li>
<li>同【ai1】可以训练在不同$P_T,\sigma_k$环境下的$\mathbf V$，以增强鲁棒性</li>
</ul>
</li>
</ul>
<h3 id="Contributions-1"><a href="#Contributions-1" class="headerlink" title="Contributions"></a>Contributions</h3><ul>
<li>We propose a framework for deep-unfolding, where the general form of IAIDNN is developed in matrix form to better solve the problems in communication systems. To train the IAIDNN, <strong>the GCR is proposed to calculate the gradients of the trainable parameters.</strong></li>
<li>We implement the proposed deep-unfolding framework to solve the sum-rate maximization problem for precoding design in MU-MIMO systems. Based on the structure of the iterative WMMSE algorithm, an efficient IAIDNN is developed, where <strong>the iterative WMMSE algorithm is unfolded into a layer-wise structure.</strong></li>
<li>We analyze the computational complexity and generalization ability of the proposed schemes. Simulation results show that the proposed IAIDNN efficiently achieves the performance of the iterative WMMSE algorithm with reduced computational complexity. The contribution becomes more significant in a massive MU-MIMO system.</li>
</ul>
<blockquote>
<ol>
<li>model-driven</li>
<li>反向传播——矩阵形式的广义链式法则</li>
</ol>
</blockquote>
<hr>
<h2 id="DL-DSC-FDD-Massive-MIMO——2021-TWC"><a href="#DL-DSC-FDD-Massive-MIMO——2021-TWC" class="headerlink" title="DL-DSC-FDD-Massive-MIMO——2021-TWC"></a>DL-DSC-FDD-Massive-MIMO——2021-TWC</h2><p><em>Deep Learning for Distributed Channel Feedback and Multiuser Precoding in FDD Massive MIMO</em>——imperfect CSI</p>
<p>MU-MISO<br>$$<br>\begin{aligned}<br>\underset{\tilde{\mathbf{X}},\left{\mathcal{F}<em>{k}(\cdot)\right}</em>{\forall k}, \mathcal{P}(\cdot)}{\operatorname{maximize}} \quad &amp; \sum_{k&#x3D;1}^{K} \log <em>{2}\left(1+\frac{\left|\mathbf{h}</em>{k}^{H} \mathbf{v}<em>{k}\right|^{2}}{\sum</em>{j \neq k}\left|\mathbf{h}<em>{k}^{H} \mathbf{v}</em>{j}\right|^{2}+\sigma^{2}}\right) \<br>\text { subject to } \quad &amp; \mathbf{V}&#x3D;\mathcal{P}\left(\left[\mathbf{q}<em>{1}^{T}, \ldots, \mathbf{q}</em>{K}^{T}\right]^{T}\right) \<br>&amp; \mathbf{q}<em>{k}&#x3D;\mathcal{F}</em>{k}\left(\mathbf{h}<em>{k}^{H} \widetilde{\mathbf{X}}+\widetilde{\mathbf{z}}</em>{k}\right), \quad \forall k \<br>&amp; \operatorname{Tr}\left(\mathbf{V} \mathbf{V}^{H}\right) \leq P \<br>&amp;\left|\widetilde{\mathbf{x}}<em>{\ell}\right|</em>{2}^{2} \leq P, \quad \forall \ell<br>\end{aligned}<br>$$<br>其中，$\tilde{\mathbf{X}}$是下行链路训练导频，$\mathcal{F}_k:\mathbb{C}^{1\times L}\to {\pm 1}^B$表示第$k$个用户的反馈策略，$\mathbf{q}_k$是$B$位反馈比特用于帮助设计预编码矩阵。$\mathcal{P}:{\pm 1}^{KB}\to \mathbb{C}^{M\times K}$表示下行链路预编码策略。</p>
<p>分布式信源编码</p>
<p><img alt="image-20211125143320423" class="post-img b-lazy" data-img="/image-20211125143320423.png" data-index="18" data-src="/image-20211125143320423.png"></p>
<h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p><img alt="image-20211125143541320" class="post-img b-lazy" data-img="/image-20211125143541320.png" data-index="19" data-src="/image-20211125143541320.png"></p>
<ol>
<li>downlink training and uplink feedback phase</li>
<li>downlink data transmission phase</li>
</ol>
<h3 id="流程-2"><a href="#流程-2" class="headerlink" title="流程"></a>流程</h3><h4 id="前向传播-1"><a href="#前向传播-1" class="headerlink" title="前向传播"></a>前向传播</h4><ul>
<li><p>Downlink Pilot Training：训练参数$\widetilde{\mathbf X}$</p>
<ul>
<li>作为全连接层，训练导频$\tilde{\mathbf{X}}$看成权重矩阵，bias看作0，加上一个$\sigma^2$的加性噪声</li>
</ul>
</li>
<li><p>Uplink Feedback：（用户侧）参数$\Theta_\text{R}^{(k)}&#x3D;\left{\mathbf W_r^{(k)},\mathbf b_r^{(k)} \right}_{r&#x3D;1}^R$</p>
<ul>
<li><p>输入：<br>  $$<br>  \bar{\mathbf y}_k\triangleq[\Re{(\tilde{\mathbf y}_k)},\mathcal{I} (\tilde{\mathbf y}_k)]<br>  $$</p>
</li>
<li><p>中间层采用ReLU，最后一层用符号函数<br>  $$<br>  \mathbf{q}<em>k&#x3D;sgn\left(\mathbf W_R^{(k)}\sigma</em>{R-1}\left(\cdots\sigma_1\left(\mathbf W_1\bar{\mathbf y}_k+\mathbf b_1^{(k)}\right)\cdots\right)+\mathbf b_R^{(k)}\right)<br>  $$</p>
</li>
</ul>
</li>
<li><p>Downlink Precoding Design:    （BS侧）参数$\Theta_\text{T}&#x3D;\left{\mathbf W_t,\mathbf b_t \right}_{t&#x3D;1}^T$</p>
<ul>
<li><p>输出：<br>  $$<br>  \mathbf v&#x3D;\left[vec(\Re{(\mathbf V)})^T,vec(\mathcal{I} (\mathbf V))^T\right]T<br>  $$</p>
</li>
<li><p>中间层采用ReLU，最后一层则需要功率约束，对功率进行归一化$\tilde\sigma_T(\bullet)&#x3D;\sqrt{P}\frac{\bullet}{\left|\bullet\right|<em>2}$<br>  $$<br>  \mathbf v&#x3D;\tilde \sigma</em>{T}\left(\tilde{\mathbf W}<em>T^{(k)}\tilde \sigma</em>{T-1}\left(\cdots\tilde \sigma_1\left(\tilde {\mathbf W}_1\bar{\mathbf y}_k+\tilde{\mathbf b}_1^{(k)}\right)\cdots\right)+\tilde{\mathbf b}_T^{(k)}\right)<br>  $$</p>
</li>
</ul>
</li>
<li><p>Loss函数：对信道矩阵$\mathbf H$和下行链路训练阶段的噪声$\tilde{\mathbf z}$做期望<br>  $$<br>  \max <em>{\tilde{\mathbf{x}},{\Theta</em>{\mathrm{R}}^{(k)}}<em>{k&#x3D;1}^{K}, \Theta</em>{\mathrm{T}}} \mathbb{E}<em>{\mathbf{H}, \tilde{\mathbf z}}\left[\sum</em>{k} \log <em>{2}\left(1+\frac{\left|\mathbf{h}</em>{k}^{H} \mathbf{v}<em>{k}\right|^{2}}{\sum</em>{j \neq k}\left|\mathbf{h}<em>{k}^{H} \mathbf{v}</em>{j}\right|^{2}+\sigma^{2}}\right)\right]<br>  $$</p>
</li>
</ul>
<h4 id="反向传播-1"><a href="#反向传播-1" class="headerlink" title="反向传播"></a>反向传播</h4><ul>
<li><p>随机梯度下降SGD</p>
</li>
<li><p>针对用户侧最后一步二值化，采用slope annealing(斜率退火)的sigmoid-adjusted straight-through(sigmoid调节直通)——用sigmoid函数去表示二值函数，从而使其可微<br>  $$<br>  sgn(u)\to 2,\mathrm{sigmoid}(\alpha^{(i)}u)-1&#x3D;\frac{2}{1+\exp(-\alpha^{i}u)}-1<br>  $$<br>  其中，$\alpha^{(i)}$是第$i$个epoch中的退火因子，$\alpha^{(i)}\geq\alpha^{(i-1)}$</p>
</li>
</ul>
<h4 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h4><p><img alt="image-20211126103118589" class="post-img b-lazy" data-img="/image-20211126103118589.png" data-index="20" data-src="/image-20211126103118589.png"></p>
<ul>
<li>用户侧和BS侧均为$R&#x3D;T&#x3D;4$层网络，用户侧$[1024,512,256,B]$，BS侧$[1024,512,512,2MK]$</li>
</ul>
<h3 id="泛化能力（🌟）"><a href="#泛化能力（🌟）" class="headerlink" title="泛化能力（🌟）"></a>泛化能力（🌟）</h3><ul>
<li>B（反馈的编码位数）<ul>
<li>用户侧通过tanh输出$S$个$[-1,1]$间的软二进制值，通过一定的$Q-bit$量化方式，传送到BS侧（$B&#x3D;S\times Q$，原来是传递B位二进制值，现在改为S位Q进制值）——相当于在用户侧DNN输出后加了个量化器</li>
<li>BS侧根据$KS$个Q进制量化的值，映射到$M\times K$的预编码矩阵（原来是通过$KB$个二进制${\pm1}$量化值映射到$M\times K$的预编码矩阵）</li>
</ul>
</li>
<li>K（用户数量）<ul>
<li>每个用户信道分布i.i.d.，则只需要训练一个用户侧的DNN</li>
<li>分两个阶段：先利用单用户系统，训练导频$\tilde{\mathbf X}$和用户侧的网络；再针对多用户系统（训练导频和用户侧网络复制）训练BS侧网络。</li>
</ul>
</li>
</ul>
<h3 id="仿真-3"><a href="#仿真-3" class="headerlink" title="仿真"></a>仿真</h3><h4 id="基准算法"><a href="#基准算法" class="headerlink" title="基准算法"></a>基准算法</h4><p><img alt="image-20211126131819631" class="post-img b-lazy" data-img="/image-20211126131819631.png" data-index="21" data-src="/image-20211126131819631.png"></p>
<ul>
<li>训练的DNN具备减小频分双工多用户系统用户间干扰的能力</li>
<li>先估计后量化信道参数是有限导频长度下的次优解</li>
<li>导频长度长，能逼近最优解，且本文方法的SR一般更高</li>
</ul>
<h4 id="L-p-的泛化能力"><a href="#L-p-的泛化能力" class="headerlink" title="$L_p$的泛化能力"></a>$L_p$的泛化能力</h4><ul>
<li>训练集和测试集的不匹配，会导致表现恶化</li>
<li>在更大范围的信道参数上训练DNN，能在无关于信道参数的先验条件时帮助我们设计更鲁棒的网络。</li>
</ul>
<h4 id="B-的泛化能力"><a href="#B-的泛化能力" class="headerlink" title="$B$的泛化能力"></a>$B$的泛化能力</h4><p>通过上面的设计，只有微不足道的损失。但同时能帮助神经网络提升在反馈容量方面的泛化能力。</p>
<h4 id="K-的泛化能力"><a href="#K-的泛化能力" class="headerlink" title="$K$的泛化能力"></a>$K$的泛化能力</h4><ul>
<li>DNN远好于其它有限下行链路训练资源</li>
<li>两步实现和end-to-end差异不大</li>
</ul>

                </article>
                <ul class="tags-postTags">
                    
                    <li>
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
                    </li>
                    
                    <li>
                        <a href="/tags/%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1/" rel="tag"># 无线通信</a>
                    </li>
                    
                    <li>
                        <a href="/tags/MIMO/" rel="tag"># MIMO</a>
                    </li>
                    
                    <li>
                        <a href="/tags/%E9%A2%84%E7%BC%96%E7%A0%81/" rel="tag"># 预编码</a>
                    </li>
                    
                </ul>
            </div>
        </div>
    </div>
    
    
    <div>
        <div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script type="text/javascript" src="http://jslibs.wuxubj.cn/sweetalert_mini/jquery-1.7.1.min.js"></script>
  <script src="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.min.js"></script>
  <link rel="stylesheet" type="text/css" href="http://jslibs.wuxubj.cn/sweetalert_mini/sweetalert.mini.css">

  <p><span>本文标题:</span>【预编码论文阅读（二）】深度学习(一)</p>
  <p><span>文章作者:</span>Levitate_</p>
  <p><span>发布时间:</span>2021年12月07日 - 20:14:02</p>
  <p><span>原始链接:</span><a href="/2021/12/08/precoding-2/" title="【预编码论文阅读（二）】深度学习(一)">https://levitate-qian.github.io/2021/12/08/precoding-2/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://levitate-qian.github.io/2021/12/08/precoding-2/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
    clipboard.on('success', $(function(){
      $(".fa-clipboard").click(function(){
        swal({   
          title: "",   
          text: '复制成功',   
          html: false,
          timer: 500,   
          showConfirmButton: false
        });
      });
    }));  
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
    </div>
    
    

    
    <nav id="gobottom" class="pagination">
        
        <a class="prev-post" title="【预编码论文阅读（三）】深度学习(二)" href="/2022/01/06/procoding-3/">
            ← 【预编码论文阅读（三）】深度学习(二)
        </a>
        
        <span class="prev-next-post">·</span>
        
        <a class="next-post" title="【预编码论文阅读（一）】传统方法" href="/2021/12/08/precoding-1/">
            【预编码论文阅读（一）】传统方法 →
        </a>
        
    </nav>

    
    <div class="inner">
        <div id="comment"></div>
    </div>
    
</div>

<div class="toc-bar">
    <div class="toc-btn-bar">
        <a href="#site-main" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M793.024 710.272a32 32 0 1 0 45.952-44.544l-310.304-320a32 32 0 0 0-46.4 0.48l-297.696 320a32 32 0 0 0 46.848 43.584l274.752-295.328 286.848 295.808z"/></svg>
        </a>
        <div class="toc-btn toc-switch">
            <svg class="toc-open" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M779.776 480h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M779.776 672h-387.2a32 32 0 0 0 0 64h387.2a32 32 0 0 0 0-64M256 288a32 32 0 1 0 0 64 32 32 0 0 0 0-64M392.576 352h387.2a32 32 0 0 0 0-64h-387.2a32 32 0 0 0 0 64M256 480a32 32 0 1 0 0 64 32 32 0 0 0 0-64M256 672a32 32 0 1 0 0 64 32 32 0 0 0 0-64"/></svg>
            <svg class="toc-close hide" viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M512 960c-247.039484 0-448-200.960516-448-448S264.960516 64 512 64 960 264.960516 960 512 759.039484 960 512 960zM512 128.287273c-211.584464 0-383.712727 172.128262-383.712727 383.712727 0 211.551781 172.128262 383.712727 383.712727 383.712727 211.551781 0 383.712727-172.159226 383.712727-383.712727C895.712727 300.415536 723.551781 128.287273 512 128.287273z"/><path d="M557.05545 513.376159l138.367639-136.864185c12.576374-12.416396 12.672705-32.671738 0.25631-45.248112s-32.704421-12.672705-45.248112-0.25631l-138.560301 137.024163-136.447897-136.864185c-12.512727-12.512727-32.735385-12.576374-45.248112-0.063647-12.512727 12.480043-12.54369 32.735385-0.063647 45.248112l136.255235 136.671523-137.376804 135.904314c-12.576374 12.447359-12.672705 32.671738-0.25631 45.248112 6.271845 6.335493 14.496116 9.504099 22.751351 9.504099 8.12794 0 16.25588-3.103239 22.496761-9.247789l137.567746-136.064292 138.687596 139.136568c6.240882 6.271845 14.432469 9.407768 22.65674 9.407768 8.191587 0 16.352211-3.135923 22.591372-9.34412 12.512727-12.480043 12.54369-32.704421 0.063647-45.248112L557.05545 513.376159z"/></svg>
        </div>
        <a href="#gobottom" class="toc-btn">
            <svg viewbox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M231.424 346.208a32 32 0 0 0-46.848 43.584l297.696 320a32 32 0 0 0 46.4 0.48l310.304-320a32 32 0 1 0-45.952-44.544l-286.848 295.808-274.752-295.36z"/></svg>
        </a>
    </div>
    <div class="toc-main">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#预编码论文阅读（二）——深度学习（一）"><span class="toc-text">预编码论文阅读（二）——深度学习（一）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Beamforming-Design-for-Large-Scale-Antenna-Arrays-Using-Deep-Learning——2020"><span class="toc-text">Beamforming Design for Large-Scale Antenna Arrays Using Deep Learning——2020</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#流程"><span class="toc-text">流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#网络结构"><span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法复杂度"><span class="toc-text">算法复杂度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#仿真"><span class="toc-text">仿真</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Contribution"><span class="toc-text">Contribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#改进思路"><span class="toc-text">改进思路</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-Deep-Learning-Framework-for-Optimization-of-MISO-Downlink-Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM"><span class="toc-text">A Deep Learning Framework for Optimization of MISO Downlink Beamforming——2020【是否可以改成transfer？共用前面网络层的参数】-TCOMM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#网络框架"><span class="toc-text">网络框架</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P1（功率约束下SINR平衡）的网络——supervised"><span class="toc-text">P1（功率约束下SINR平衡）的网络——supervised</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P2（服务质量约束下功率最小）的网络"><span class="toc-text">P2（服务质量约束下功率最小）的网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P3（功率约束下SR最高）的网络"><span class="toc-text">P3（功率约束下SR最高）的网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#仿真-1"><span class="toc-text">仿真</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#contributions"><span class="toc-text">contributions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#改进思路——针对SR的思考"><span class="toc-text">改进思路——针对SR的思考</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Learning-Enabled-Optimization-of-Downlink-Beamforming-Under-Per-Antenna-Power-Constraints-Algorithms-and-Experimental-Demonstration——2020-TWC"><span class="toc-text">Deep Learning Enabled Optimization of Downlink Beamforming Under Per-Antenna Power Constraints: Algorithms and Experimental Demonstration——2020-TWC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#单天线约束下的SINR-balancing问题："><span class="toc-text">单天线约束下的SINR balancing问题：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#流程-1"><span class="toc-text">流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#仿真-2"><span class="toc-text">仿真</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Contributions"><span class="toc-text">Contributions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#IAIDNN——2021-TWC"><span class="toc-text">IAIDNN——2021-TWC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#深度展开网络的搭建"><span class="toc-text">深度展开网络的搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IWMMSE算法的转换"><span class="toc-text">IWMMSE算法的转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#IAIDNN-iterative-algorithm-induced-Deep-Unfolding-Neural-Network"><span class="toc-text">IAIDNN(iterative algorithm induced Deep-Unfolding Neural Network)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#前向传播"><span class="toc-text">前向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#反向传播"><span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#算法流程"><span class="toc-text">算法流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#benchmark——CNN"><span class="toc-text">benchmark——CNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分析"><span class="toc-text">分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Contributions-1"><span class="toc-text">Contributions</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DL-DSC-FDD-Massive-MIMO——2021-TWC"><span class="toc-text">DL-DSC-FDD-Massive-MIMO——2021-TWC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#网络结构-1"><span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#流程-2"><span class="toc-text">流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#前向传播-1"><span class="toc-text">前向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#反向传播-1"><span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#算法流程-1"><span class="toc-text">算法流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#泛化能力（🌟）"><span class="toc-text">泛化能力（🌟）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#仿真-3"><span class="toc-text">仿真</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#基准算法"><span class="toc-text">基准算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#L-p-的泛化能力"><span class="toc-text">$L_p$的泛化能力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#B-的泛化能力"><span class="toc-text">$B$的泛化能力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#K-的泛化能力"><span class="toc-text">$K$的泛化能力</span></a></li></ol></li></ol></li></ol></li></ol>
    
    </div>
</div>



<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>




	</div>
	


<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
            

<article class="read-next-card" style="background-image: url(https://s1.ax1x.com/2020/08/09/a7ycNV.png)">
  <header class="read-next-card-header">
    <small class="read-next-card-header-sitetitle">&mdash; Levitate_ &mdash;</small>
    <h3 class="read-next-card-header-title">最新文章</h3>
  </header>
  <div class="read-next-divider">
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
      <path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/>
    </svg>
  </div>
  <div class="read-next-card-content">
    <ul>
      
      
      
      <li>
        <a href="/2022/12/05/SEU-note/">【持续更新】研究生期间笔记整理</a>
      </li>
      
      
      
      <li>
        <a href="/2022/09/17/git-ssh/">git基本操作整理与VScode ssh配置远程服务器</a>
      </li>
      
      
      
      <li>
        <a href="/2022/08/24/undergraduate-media-achievements/">本科期间推文、视频等汇总</a>
      </li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
  <footer class="read-next-card-footer">
    <a href="/archives">  MORE  → </a>
  </footer>
</article>

            
            
            

<article class="read-next-card" style="background-image: url(https://s1.ax1x.com/2020/08/09/a7ycNV.png)">
    <header class="read-next-card-header tagcloud-card">
        <h3 class="read-next-card-header-title">分类</h3>
    </header>
    <div class="read-next-card-content">
        <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/LaTeX/">LaTeX</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C/">实验</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%80%BB%E7%BB%93/">总结</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></li></ul>
    </div>
</article>


            
            
            

<article class="read-next-card" style="background-image: url(https://s1.ax1x.com/2020/08/09/a7ycNV.png)">
	<header class="read-next-card-header tagcloud-card">
		<h3 class="read-next-card-header-title">标签云</h3>
	</header>
	<div class="read-next-card-content-ext">
		<a href="/tags/AI/" style="font-size: 19px;">AI</a> <a href="/tags/MATLAB/" style="font-size: 15.67px;">MATLAB</a> <a href="/tags/MIMO/" style="font-size: 19px;">MIMO</a> <a href="/tags/Vscode/" style="font-size: 15.67px;">Vscode</a> <a href="/tags/git/" style="font-size: 14px;">git</a> <a href="/tags/iPad/" style="font-size: 14px;">iPad</a> <a href="/tags/ssh/" style="font-size: 14px;">ssh</a> <a href="/tags/%E4%BF%A1%E5%8F%B7/" style="font-size: 14px;">信号</a> <a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 14px;">博客</a> <a href="/tags/%E5%A4%A7%E5%AD%A6/" style="font-size: 14px;">大学</a> <a href="/tags/%E5%B0%84%E9%A2%91/" style="font-size: 15.67px;">射频</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" style="font-size: 19px;">数学建模</a> <a href="/tags/%E6%97%A0%E7%BA%BF%E9%80%9A%E4%BF%A1/" style="font-size: 22.33px;">无线通信</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 17.33px;">机器学习</a> <a href="/tags/%E6%A8%A1%E6%8B%9F%E7%94%B5%E5%AD%90%E6%8A%80%E6%9C%AF/" style="font-size: 15.67px;">模拟电子技术</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 20.67px;">深度学习</a> <a href="/tags/%E7%94%B5%E7%A3%81%E5%9C%BA%E4%B8%8E%E7%94%B5%E7%A3%81%E6%B3%A2/" style="font-size: 17.33px;">电磁场与电磁波</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 15.67px;">神经网络</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 24px;">论文</a> <a href="/tags/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/" style="font-size: 15.67px;">通信原理</a> <a href="/tags/%E9%A2%84%E7%BC%96%E7%A0%81/" style="font-size: 17.33px;">预编码</a>
	</div>
</article>

            
        </div>
    </div>
</aside>

	




<div id="search" class="search-overlay">
    <div class="search-form">
        
        <div class="search-overlay-logo">
        	<img src="https://s1.ax1x.com/2022/05/18/Oo3OeI.png" alt="Levitate_">
        </div>
        
        <input id="local-search-input" class="search-input" type="text" name="search" placeholder="搜索 ...">
        <a class="search-overlay-close" href="#"></a>
    </div>
    <div id="local-search-result"></div>
</div>

<footer class="site-footer outer">
	<div class="site-footer-content inner">
		<div class="copyright">
			<a href="/" title="Levitate_">Levitate_ &copy; 2022</a>
			
				
			        <span hidden="true" id="/2021/12/08/precoding-2/" class="leancloud-visitors" data-flag-title="【预编码论文阅读（二）】深度学习(一)">
			            <span>阅读量 </span>
			            <span class="leancloud-visitors-count">0</span>
			        </span>
	    		
    		
		</div>
		<nav class="site-footer-nav">
			
			<a href="/atom.xml" title="RSS" target="_blank" rel="noopener">RSS</a>
			
			<a href="https://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
			<a href="https://github.com/xzhih/hexo-theme-casper" title="Casper" target="_blank" rel="noopener">Casper</a>
		</nav>
	</div>
</footer>
	


<script>
    if(window.navigator && navigator.serviceWorker) {
        navigator.serviceWorker.getRegistrations().then(function(registrations) {
            for(let registration of registrations) {
                registration.unregister()
            }
        })
    }
</script>


<script id="scriptLoad" src="/js/allinone.min.js" async></script>



<div class="floating-header">
	<div class="floating-header-logo">
        <a href="/" title="Levitate_">
			
                <img src="https://s1.ax1x.com/2022/05/18/Oo3OeI.png" alt="Levitate_ icon">
			
            <span>Levitate_</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">【预编码论文阅读（二）】深度学习(一)</div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>




<script>;(function() {var bLazy = new Blazy()})();</script>




<script>
    document.getElementById('scriptLoad').addEventListener('load', function () {
        
        
            var bLazy = new Blazy();
        

        
        

        
        
        
            searchFunc("/");
        
        
    })
</script>




<link rel="stylesheet" href="/photoswipe/photoswipe.css">


<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>


<script src="/photoswipe/photoswipe-ui-default.min.js"></script>





<script id="valineScript" src="//unpkg.com/valine/dist/Valine.min.js" async></script>
<script>
    document.getElementById('valineScript').addEventListener("load", function() {
        new Valine({
            el: '#comment' ,
            verify: false,
            notify: false,
            appId: 'lv1bzqDwJo9FTYdBip3QGP7t-gzGzoHsz',
            appKey: 'mK4QC79PTUYTSginf9BXEzlv',
            placeholder: '求轻喷(*/ω＼*)',
            pageSize: 10,
            avatar: 'retro',
            visitor: true,
            requiredFields: ['mail']
        })
    });
</script>




<script>
    document.addEventListener('DOMContentLoaded',function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    });
</script>


</body>
</html>
